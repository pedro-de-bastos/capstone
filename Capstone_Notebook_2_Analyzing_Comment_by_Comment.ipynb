{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone Notebook 2: Analyzing Comment by Comment.ipynb",
      "provenance": [],
      "mount_file_id": "1TV303YvEsJ2g6-Jz-8OnVAgbmMJslhzq",
      "authorship_tag": "ABX9TyPnzkHb7+21DnWNRlSFX8kS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedro-de-bastos/Capstone/blob/master/Capstone_Notebook_2_Analyzing_Comment_by_Comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKpThRihbWOb",
        "outputId": "97fe7368-efc4-4aab-fb7f-80925e03fd57"
      },
      "source": [
        "!pip install google.cloud\n",
        "!pip install pystan\n",
        "import pystan\n",
        "import pandas as pd\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import path\n",
        "import glob\n",
        "import numpy as np\n",
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as sts\n",
        "%matplotlib inline\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/Capstone/instructor-langu-1590688665393-6d06375c82af.json'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google.cloud\n",
            "  Using cached https://files.pythonhosted.org/packages/ba/b1/7c54d1950e7808df06642274e677dbcedba57f75307adf2e5ad8d39e5e0e/google_cloud-0.34.0-py2.py3-none-any.whl\n",
            "Installing collected packages: google.cloud\n",
            "Successfully installed google.cloud\n",
            "Requirement already satisfied: pystan in /usr/local/lib/python3.7/dist-packages (2.19.1.1)\n",
            "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan) (0.29.22)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvosAr6vcN1u"
      },
      "source": [
        "def response_sentiment_analysis(string_response):\n",
        "  text_content = string_response\n",
        "\n",
        "  # Available types: PLAIN_TEXT, HTML\n",
        "  type_ = enums.Document.Type.PLAIN_TEXT\n",
        "\n",
        "  # Optional. If not specified, the language is automatically detected.\n",
        "  # For list of supported languages:\n",
        "  # https://cloud.google.com/natural-language/docs/languages\n",
        "  language = \"en\"\n",
        "  document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
        "\n",
        "  # Available values: NONE, UTF8, UTF16, UTF32\n",
        "  encoding_type = enums.EncodingType.UTF8\n",
        "\n",
        "  client = language_v1.LanguageServiceClient()\n",
        "  annotations = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
        "  return(annotations)\n",
        "\n",
        "def get_score(text):\n",
        "  sa = response_sentiment_analysis(text)\n",
        "  return sa.document_sentiment.score\n",
        "\n",
        "def get_magnitude(text):\n",
        "  sa = response_sentiment_analysis(text)\n",
        "  return sa.document_sentiment.magnitude\n",
        "\n",
        "def prep_data(file_path):\n",
        "  foo = pd.read_csv(file_path)\n",
        "  foo['Transcripts'] = foo['Transcripts'].astype(str)\n",
        "  foo['Score'] = foo['Transcripts'].apply(get_score)\n",
        "  foo['Magnitude'] = foo['Transcripts'].apply(get_magnitude)\n",
        "  foo['Duration Secs'] = foo['Duration Secs']/1000\n",
        "  foo['Timestamp'] = foo['Timestamp']/1000\n",
        "  foo['End'] = foo['End']/1000\n",
        "  foo['Judgement'] = foo['Score']*foo['Magnitude']\n",
        "  return foo\n",
        "\n",
        "def list_sessions():\n",
        "  sessions = []\n",
        "\n",
        "  for i in range(1, 11):\n",
        "    for j in range(1, 3):\n",
        "      session = 'Class_{}.{}'.format(i, j)\n",
        "      if session != 'Class_6.1':\n",
        "        sessions.append(session)\n",
        "  return sessions\n",
        "\n",
        "def list_sess_num():\n",
        "  lst_sess_num = []\n",
        "  for i in range(1,11):\n",
        "    for j in range(1, 3):\n",
        "      if \"{}.{}\".format(i, j)!=\"6.1\":\n",
        "        lst_sess_num.append(\"{}.{}\".format(i, j))\n",
        "  return lst_sess_num\n",
        "\n",
        "def create_class_to_date_dic(emojis_handraises):\n",
        "  sessions = list_sessions()\n",
        "\n",
        "  class_dates = emojis_handraises['Class Date'].unique()\n",
        "  class_dates = np.flip(class_dates)[0:20]\n",
        "\n",
        "  dic = {}\n",
        "  for i, j in zip(sessions, class_dates):\n",
        "    dic[j] = i\n",
        "  return dic\n",
        "\n",
        "def mapper(class_date, emojis_handraises):\n",
        "  dic = create_class_to_date_dic(emojis_handraises)\n",
        "  try:\n",
        "    return dic[class_date]\n",
        "  except: \n",
        "    return np.nan\n",
        "\n",
        "def prep_emojis(file_path, session, class_start_hour):\n",
        "  emojis_handraises = pd.read_csv(file_path)\n",
        "  emojis_handraises['Sessions'] = emojis_handraises['Class Date'].apply(mapper, args=(emojis_handraises,))\n",
        "  emojis_handraises = emojis_handraises.dropna(axis=0)\n",
        "  emojis_handraises = emojis_handraises[emojis_handraises['Sessions']==\"Class_{}\".format(session)]\n",
        "  emojis_handraises['Start Time'] = pd.to_datetime(emojis_handraises['Start Time'])\n",
        "  emojis_handraises['Start Time'] = emojis_handraises['Start Time'].apply(adjust_time, args=(class_start_hour,))\n",
        "  return emojis_handraises\n",
        "\n",
        "def adjust_time(x, class_start):\n",
        "  class_start_seconds = (class_start-1)*3600+59*60\n",
        "  event_seconds = x.hour*3600+x.minute*60+x.second\n",
        "  return event_seconds - class_start_seconds\n",
        "\n",
        "def events_counter(end, event_type, emojis):\n",
        "  emojis = emojis[np.logical_and(emojis['Start Time']>(end-20), emojis['Start Time']<(end+40))]\n",
        "  emojis = emojis[emojis['Event Data']==event_type]\n",
        "  return emojis.shape[0]\n",
        "\n",
        "def merge_data(emojis, foo):\n",
        "  unique_events = ['{\"emotion\":\"confused\"}', '{\"emotion\":\"frown\"}', '{\"emotion\":\"hand-raise\"}', '{\"emotion\":\"lol\"}', '{\"emotion\":\"smile\"}', '{\"emotion\":\"snap\"}', '{\"emotion\":\"thumbsdown\"}']\n",
        "  for i in unique_events:\n",
        "    foo[i] = foo['End'].apply(events_counter, args=(i, emojis))\n",
        "  return foo\n",
        "\n",
        "def produce_emojis_data(lst):\n",
        "  datas = {}\n",
        "\n",
        "  for i, j in zip(lst, list_sess_num()):\n",
        "    if '/content/drive/MyDrive/Capstone/{}/SliceFoos/foo_{}.csv'.format(lst[0].split('/')[5], j) not in glob.glob(f\"/content/drive/MyDrive/Capstone/{lst[0].split('/')[5]}/SliceFoos/*\"):\n",
        "      foo = prep_data(i)\n",
        "      foo['Session Number'] = \"Class_{}\".format(j)\n",
        "      emojis = prep_emojis(f\"/content/drive/MyDrive/Capstone/{lst[0].split('/')[5]}/Emoji and Hand Raises/emoji_hands.csv\", j, 11)\n",
        "      datas[j] = merge_data(emojis, foo)\n",
        "      foo.to_csv('/content/drive/MyDrive/Capstone/{}/SliceFoos/foo_{}.csv'.format(lst[0].split('/')[5], j))\n",
        "    else:\n",
        "      emojis = prep_emojis(f\"/content/drive/MyDrive/Capstone/{lst[0].split('/')[5]}/Emoji and Hand Raises/emoji_hands.csv\", j, 11)\n",
        "      foo = pd.read_csv('/content/drive/MyDrive/Capstone/{}/SliceFoos/foo_{}.csv'.format(lst[0].split('/')[5], j))\n",
        "      datas[j] = merge_data(emojis, foo)\n",
        "  return datas\n",
        "\n",
        "def produce_and_merge(lst):\n",
        "  csvs = produce_emojis_data(lst)\n",
        "  csvs_lst = []\n",
        "  for i in list_sess_num():\n",
        "    csvs_lst.append(csvs[i])\n",
        "  concat_csvs = pd.concat(csvs_lst)\n",
        "  concat_csvs['Engagement'] = concat_csvs['{\"emotion\":\"confused\"}']+concat_csvs['{\"emotion\":\"frown\"}']+concat_csvs['{\"emotion\":\"hand-raise\"}']+concat_csvs['{\"emotion\":\"lol\"}']+concat_csvs['{\"emotion\":\"smile\"}']+concat_csvs['{\"emotion\":\"snap\"}']+concat_csvs['{\"emotion\":\"thumbsdown\"}']\n",
        "  return concat_csvs\n",
        "\n",
        "def emotion_lst():\n",
        "  return ['{\"emotion\":\"confused\"}', '{\"emotion\":\"frown\"}', '{\"emotion\":\"hand-raise\"}', '{\"emotion\":\"lol\"}', '{\"emotion\":\"smile\"}', '{\"emotion\":\"snap\"}', '{\"emotion\":\"thumbsdown\"}']\n",
        "\n",
        "def plot_emotions(concat_data):\n",
        "  emotions = ['{\"emotion\":\"confused\"}', '{\"emotion\":\"frown\"}', '{\"emotion\":\"hand-raise\"}', '{\"emotion\":\"lol\"}', '{\"emotion\":\"smile\"}', '{\"emotion\":\"snap\"}', '{\"emotion\":\"thumbsdown\"}']\n",
        "  fig, axs = plt.subplots(nrows = 3, ncols=3, figsize=(30, 10))\n",
        "  #fig.suptitle('Emotions and Occurences')\n",
        "  colors = ['red', 'green', 'blue', 'orange', 'purple', 'yellow', 'brown']\n",
        "\n",
        "  emot = 0\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      if emot != 7:\n",
        "        X = np.asarray(concat_data['Judgement']).reshape(-1, 1)\n",
        "        y = concat_data[emotions[emot]]\n",
        "        axs[i][j].set_xlabel(\"Sentiment Score\", fontsize=20)\n",
        "        axs[i][j].set_ylabel('Emotion Occurences', fontsize=20)\n",
        "        axs[i][j].set_title(emotions[emot], fontsize=20)\n",
        "        axs[i][j].scatter(X, y, color = colors[emot])\n",
        "        axs[i][j].tick_params(axis=\"y\", labelsize=20)\n",
        "        axs[i][j].tick_params(axis=\"x\", labelsize=20)\n",
        "        emot += 1\n",
        "  axs[2][1].set_xlabel(\"Sentiment Score\", fontsize=20)\n",
        "  axs[2][1].set_ylabel('Emotion Occurences', fontsize=20)\n",
        "  axs[2][1].set_title(emotions[6], fontsize=20)\n",
        "  axs[2][1].scatter(X, y, color = colors[6])\n",
        "  axs[2][1].tick_params(axis=\"y\", labelsize=20)\n",
        "  axs[2][1].tick_params(axis=\"x\", labelsize=20)\n",
        "  fig.delaxes(axs[2][2])\n",
        "  fig.delaxes(axs[2][0])\n",
        "  fig.subplots_adjust(top = 0.9, bottom = -0.7, wspace=0.3, hspace=0.4)\n",
        "  plt.show()\n",
        "\n",
        "def hists_2d(concat_data):\n",
        "  bin = 15\n",
        "  emotions = ['{\"emotion\":\"confused\"}', '{\"emotion\":\"frown\"}', '{\"emotion\":\"hand-raise\"}', '{\"emotion\":\"lol\"}', '{\"emotion\":\"smile\"}', '{\"emotion\":\"snap\"}', '{\"emotion\":\"thumbsdown\"}']\n",
        "  fig, axs = plt.subplots(nrows = 3, ncols=3, figsize=(30, 10))\n",
        "  #fig.suptitle('Emotions and Occurences')\n",
        "  colors = ['red', 'green', 'blue', 'orange', 'purple', 'yellow', 'brown']\n",
        "\n",
        "  emot = 0\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      if emot != 7:\n",
        "        X = concat_data['Judgement']\n",
        "        y = concat_data[emotions[emot]]\n",
        "        axs[i][j].set_xlabel(\"Sentiment Score\", fontsize=20)\n",
        "        axs[i][j].set_ylabel('Emotion Occurences', fontsize=20)\n",
        "        axs[i][j].set_title(emotions[emot], fontsize=20)\n",
        "        axs[i][j].hist2d(X, y, bins=[bin, bin], density=True)\n",
        "        axs[i][j].tick_params(axis=\"y\", labelsize=20)\n",
        "        axs[i][j].tick_params(axis=\"x\", labelsize=20)\n",
        "        emot += 1\n",
        "  axs[2][1].set_xlabel(\"Sentiment Score\", fontsize=20)\n",
        "  axs[2][1].set_ylabel('Emotion Occurences', fontsize=20)\n",
        "  axs[2][1].set_title(emotions[6], fontsize=20)\n",
        "  axs[2][1].hist2d(X, y, bins=[bin, bin], density=True)\n",
        "  axs[2][1].tick_params(axis=\"y\", labelsize=20)\n",
        "  axs[2][1].tick_params(axis=\"x\", labelsize=20)\n",
        "  fig.delaxes(axs[2][2])\n",
        "  fig.delaxes(axs[2][0])\n",
        "  fig.subplots_adjust(top = 0.9, bottom = -0.7, wspace=0.3, hspace=0.4)\n",
        "  plt.show()\n",
        "\n",
        "def run_chi2(concat, emoji):\n",
        "  concat[emoji]\n",
        "  upper = concat['Judgement'].mean()+concat['Judgement'].std()\n",
        "  lower = concat['Judgement'].mean()-concat['Judgement'].std()\n",
        "\n",
        "  positive = concat[concat['Judgement']>upper]\n",
        "  negative = concat[concat['Judgement']<lower]\n",
        "  neutral = concat[np.logical_and(concat['Judgement']<upper, concat['Judgement']>lower)]\n",
        "\n",
        "  positive.high = sum(positive[emoji]>3)\n",
        "  positive.low = sum(positive[emoji]<=3)\n",
        "\n",
        "  neutral.high = sum(neutral[emoji]>3)\n",
        "  neutral.low = sum(neutral[emoji]<=3)\n",
        "\n",
        "  negative.high = sum(negative[emoji]>3)\n",
        "  negative.low = sum(negative[emoji]<=3)\n",
        "\n",
        "  matrix = np.asarray([[neutral.high, neutral.low], [positive.high, positive.low], [negative.high, negative.low]])\n",
        "  test = sts.chi2_contingency(matrix)\n",
        "  return test, matrix\n",
        "\n",
        "def create_pos_neut_neg(concat):   \n",
        "  positive_thresh = concat_mcallister['Judgement'].mean()+concat_mcallister['Judgement'].std()\n",
        "  negative_thresh = concat_mcallister['Judgement'].mean()-concat_mcallister['Judgement'].std()\n",
        "\n",
        "  positive = concat_mcallister[concat_mcallister['Judgement']>positive_thresh]\n",
        "  negative = concat_mcallister[concat_mcallister['Judgement']<negative_thresh]\n",
        "  neutral = concat_mcallister[(concat_mcallister['Judgement']>negative_thresh)&(concat_mcallister['Judgement']<positive_thresh)]\n",
        "\n",
        "  return positive, neutral, negative\n",
        "\n",
        "def stat_diff_pos_neut_neg(concat):\n",
        "  positive, neutral, negative = create_pos_neut_neg(concat)\n",
        "  results = pd.DataFrame(columns=['Number of Comments', 'Mean Engagement', 'Independence T-Test with Positive', 'Independence T-Test with Neutral', 'Independence T-Test with Negative'])\n",
        "\n",
        "  results['Number of Comments'] = pd.Series([i.shape[0] for i in [positive, neutral, negative]])\n",
        "  results['Mean Engagement'] = pd.Series([i['Engagement'].mean() for i in [positive, neutral, negative]])\n",
        "  results['Independence T-Test with Positive'] = pd.Series([sts.ttest_ind(i['Engagement'], positive['Engagement']).pvalue for i in [positive, neutral, negative]])\n",
        "  results['Independence T-Test with Neutral'] = pd.Series([sts.ttest_ind(i['Engagement'], neutral['Engagement']).pvalue for i in [positive, neutral, negative]])\n",
        "  results['Independence T-Test with Negative'] = pd.Series([sts.ttest_ind(i['Engagement'], negative['Engagement']).pvalue for i in [positive, neutral, negative]])\n",
        "  results.index = ['Positive', 'Neutral', 'Negative']\n",
        "  return results\n",
        "\n",
        "\n",
        "stan_code_1 = \"\"\"\n",
        "\n",
        "\n",
        "data {  \n",
        "    int<lower=0> n;  //number of comments\n",
        "    real<lower=0> comments[n]; //the number of engagements\n",
        "    real<lower=0> alpha;\n",
        "    real<lower=0> beta; \n",
        "}\n",
        "\n",
        "\n",
        "parameters {\n",
        "    real<lower=0,upper=60> lambda; //60 was arbitrary, I thought it is big enough\n",
        "                              \n",
        "}\n",
        "\n",
        "\n",
        "model {\n",
        "    lambda ~ gamma(alpha, beta);  // prior over lambda\n",
        "    for(i in 1:n)\n",
        "      comments[i] ~ exponential(lambda); //likelihood\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def compile_evaluate_stan(stan_code, concat):\n",
        "  stan_model = pystan.StanModel(model_code=stan_code) #Compiling the model\n",
        "  _, neutral, _ = create_neg_pos_neut(concat)\n",
        "  neutral = neutral['Engagement']\n",
        "  data_dict = {\"n\":len(neutral), \"comments\":neutral, \"alpha\":2, \"beta\":2}\n",
        "  stan_results = stan_model.sampling(data=data_dict)\n",
        "\n",
        "  print(stan_results)\n",
        "\n",
        "  results = stan_results.extract()['lambda']\n",
        "  return results\n",
        "\n",
        "def plot_stan_simulated_means(concat_mcallister):\n",
        "  positive, neutral, negative = create_neg_pos_neut(concat_mcallister)\n",
        "\n",
        "  samples = sts.expon.rvs(scale = 1/0.6, size=(100, 1000))\n",
        "  means = np.mean(samples, axis=0)\n",
        "  plt.hist(means, edgecolor = 'black', color = 'mediumseagreen')\n",
        "  plt.axvline(x = neutral['Engagement'].mean(), color = \"purple\", linewidth = 4, label=\"True Mean\")\n",
        "  confint = np.percentile(means, (2.5, 97.5))\n",
        "  plt.axvline(x = confint[0], color = 'y', ls = \"--\", linewidth = 4, label = \"95% Conf Int\")\n",
        "  plt.axvline(x = confint[1], color = 'y', ls = \"--\", linewidth = 4)\n",
        "  plt.xlabel(\"Simulated Mean\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.legend()\n",
        "\n",
        "def column_histograms(concat_mcallister):\n",
        "  positive, neutral, negative = create_neg_pos_neut(concat_mcallister)\n",
        "  datas = np.asarray([positive['Engagement'], negative['Engagement'], neutral['Engagement']])\n",
        "\n",
        "  plt.figure(figsize=(5,4))\n",
        "  for i, j in enumerate(datas):\n",
        "      plt.plot(sts.uniform.rvs(loc=i+1-0.2, scale=0.4, size=len(j)), \n",
        "                j, ',', alpha=0.5)\n",
        "      \n",
        "  means = [np.mean(i) for i in datas]\n",
        "\n",
        "  plt.plot(range(1, 3+1),\n",
        "          means, \n",
        "          marker='_',linewidth=0,color=\"black\",alpha=1,markersize=50)\n",
        "\n",
        "  plt.xticks(range(1, 3+1), \n",
        "            sorted([\"Positive\", \"Neutral\", \"Negative\"]))\n",
        "  plt.grid(True, alpha=0.25, axis='y')\n",
        "  plt.ylabel(\"Number of Engagements\")\n",
        "  plt.xlabel(\"Comment Sentiment\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_real_and_infered_expon_dist(concat_mcallister):\n",
        "  x = np.linspace(0, 12, num=200)\n",
        "  negative, positive, neutral = create_neg_pos_neut(concat_mcallister)\n",
        "\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  plt.hist(neutral['Engagement'], edgecolor = 'black', color='coral', density=\"True\")\n",
        "  plt.plot(x, sts.expon.pdf(x, scale=1/0.6), label='Infered Distribution')\n",
        "  plt.xlabel(\"Number of Engagements\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHL4bKSnn6Bd"
      },
      "source": [
        "lst = ['/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/1.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/1.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/2.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/2.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/3.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/3.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/4.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/4.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/5.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/5.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/6.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/7.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/7.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/8.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/8.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/9.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/9.2.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/10.1.csv', '/content/drive/MyDrive/Capstone/McAllister/Slice Analysis/10.2.csv']\n",
        "concat_mcallister = produce_and_merge(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egtPAJ3voCON"
      },
      "source": [
        "positive, neutral, negative = create_pos_neut_neg(concat_mcallister)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tv6FmWbo60B"
      },
      "source": [
        "res_pos = {}\n",
        "res_neg = {}\n",
        "res_neut = {}\n",
        "\n",
        "for i in range(14):\n",
        "  num = sum(positive['Engagement']==i)\n",
        "  res_pos[i] = num\n",
        "  num = sum(negative['Engagement']==i)\n",
        "  res_neg[i] = num\n",
        "  num = sum(neutral['Engagement']==i)\n",
        "  res_neut[i] = num\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results = results.append(res_pos, ignore_index=True)\n",
        "results = results.append(res_neg, ignore_index = True)\n",
        "results = results.append(res_neut, ignore_index=True)\n",
        "results.index = ['Positive', \"Negative\", \"Neutral\"]\n",
        "results.to_csv(\"PosNegNeutResults.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_llshuMqTB-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}