{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prototype Transcription and Sentiment Analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1UzI6Yn3fZTCuYPzDg6mO6QVWLQes_z51",
      "authorship_tag": "ABX9TyOInTTj1atTwnqWAVPvFbWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedro-de-bastos/Capstone/blob/master/Speech%20to%20Text%20Transcription%20and%20Sentiment%20Analysis%20Capstone%20Main%20Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2P7Z0m1z4oa"
      },
      "source": [
        "# Prototyping Speech-to-text Transcription and Sentiment Analysis for Instructor Tone Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoO6dG3YMXEw"
      },
      "source": [
        "## Talk Time Pre-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8fDZyVtAN6"
      },
      "source": [
        "## Transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4EYeP3c2WkI"
      },
      "source": [
        "### Installing All Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1aumQzbIILU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "7fc1af33-bc53-429d-cfef-699552a02532"
      },
      "source": [
        "#Transcription Prep - run this cell first\n",
        "#Note: this cell may ask you to reset the runtime once after it completes\n",
        "\n",
        "import os\n",
        "!pip install pydub\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install google-cloud-speech\n",
        "!pip install SpeechRecognition\n",
        "!pip install google.cloud\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.5).\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-speech) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.52.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.12.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (49.1.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2018.9)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.30.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-speech) (0.4.8)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.6/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.6/dist-packages (0.2.11)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.6/dist-packages (1.4)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.41.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.0.0)\n",
            "Collecting google.cloud\n",
            "  Using cached https://files.pythonhosted.org/packages/ba/b1/7c54d1950e7808df06642274e677dbcedba57f75307adf2e5ad8d39e5e0e/google_cloud-0.34.0-py2.py3-none-any.whl\n",
            "Installing collected packages: google.cloud\n",
            "Successfully installed google.cloud\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYEmKu3YAHG"
      },
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import glob\n",
        "import pydub\n",
        "from google.cloud import speech_v1\n",
        "from google.cloud.speech_v1 import enums\n",
        "import io\n",
        "from google.cloud.speech import types\n",
        "from google.cloud import storage\n",
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "\n",
        "\n",
        "#Note: below, I am passing a .json file containing my Google Credentials to a\n",
        "#Environment variable. This is basically allowing you to access your Google\n",
        "#Cloud console through this Python kernel. You'll have to pass your own \n",
        "#.json file location to this variable.\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/Capstone/instructor-langu-1590688665393-6d06375c82af.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br08NTBVxFxd"
      },
      "source": [
        "### Introduction: What I'm Doing and How\n",
        "In short, I am using Google Cloud for its Speech-to-text API. Google Cloud Speech-to-text has two main processes for transcribing text from an audio file: synchronous and asynchronous. Synchronous transcription is for short talks (below 1min) and asynchronous transcription is for longer talks (above 1 min). Below, I implement both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b66ebF-801JJ"
      },
      "source": [
        "### Importing the Windows Over Which the Instructor Spoke from a .csv File and Making Adjustments to the Formatting of that Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zw2hFgMM3HF"
      },
      "source": [
        "#Note that the output of the CSV file with talk times for each professor/student\n",
        "#has the timestamp expressed as a string. The function below will be used with \n",
        "#the Pandas \".apply\" method to go through each string and transform it into a \n",
        "#float, expressed in miliseconds since the start of the lesson\n",
        "def string_to_miliseconds(str):\n",
        "  mili = 0\n",
        "  lst = str.split(\":\")\n",
        "  mili += float(lst[2])*1000\n",
        "  mili += float(lst[1])*60*1000\n",
        "  mili += float(lst[0])*60*60*1000\n",
        "  return(mili)\n",
        "\n",
        "def sec_to_milisec(secs):\n",
        "  return secs*1000\n",
        "\n",
        "def windows_talk(filename):\n",
        "  foo = pd.read_csv(filename)\n",
        "  foo = foo[foo['Names'].notnull()]\n",
        "\n",
        "  foo.Timestamp = foo[\"Timestamp\"].apply(string_to_miliseconds)\n",
        "  foo[\"Duration Secs\"] = foo[\"Duration Secs\"].apply(sec_to_milisec)\n",
        "  foo['End'] = foo[\"Timestamp\"]+foo[\"Duration Secs\"] #Creating a new column that indicates when the person stopped talking\n",
        "\n",
        "  names_list = foo.Names.unique()\n",
        "  windows_dict = {}\n",
        "\n",
        "  for name in names_list:\n",
        "    individual = foo['Names'] == name\n",
        "    foo_filtered = foo[individual]\n",
        "    windows_dict[name] = foo_filtered\n",
        "  return windows_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MyWPyfc1VMN"
      },
      "source": [
        "### Cutting Out Instances of the Professor Speaking in Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8re_c4NARrbl"
      },
      "source": [
        "#Audio Pre-Processing: Cutting Audio into Instructor Talk Windows\n",
        "\n",
        "def cut_audio(src, dst, windows_dict, instructor):                                                                     \n",
        "  # importing the instructor's talk time windows and importing the audio file                                                          \n",
        "  test = AudioSegment.from_wav(src)\n",
        "  \n",
        "  try:\n",
        "    windows = windows_dict[instructor]\n",
        "    \n",
        "    for i in range(windows.shape[0]):\n",
        "      test_slice = test[windows.iloc[i,2]:windows.iloc[i,3]]\n",
        "      end = dst +'_slice_' + str(i) + \".wav\"\n",
        "      test_slice.export(end, format='wav')\n",
        "  except:\n",
        "    print(\"Instructor Name Not Valid\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UvODIJw15gY"
      },
      "source": [
        "### Joining the Extracted Professor Responses into One Long Audio For Transcription"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0BVPren7djr"
      },
      "source": [
        "def join_audios(src, dst):\n",
        "  audios = []\n",
        "  for file_name in glob.iglob(src+'_slice_**', recursive=True):\n",
        "    audios.append(file_name)\n",
        "\n",
        "  concat_audio = pydub.AudioSegment.empty()\n",
        "\n",
        "  for audio in audios:\n",
        "    concat_audio += pydub.AudioSegment.from_wav(audio)\n",
        "\n",
        "  concat_audio.export(dst, format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBcq1pm1nAs"
      },
      "source": [
        "### Defining a Function that Takes a .wav File and Transcribe it Using Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn2xGxDUBZh"
      },
      "source": [
        "#Recognizer for long files (over 1 min)\n",
        "\n",
        "def sample_long_running_recognize(storage_uri):\n",
        "    \"\"\"\n",
        "    Transcribe a long audio file using asynchronous speech recognition\n",
        "\n",
        "    Args:\n",
        "      local_file_path Path to local audio file, e.g. /path/audio.wav\n",
        "    \"\"\"\n",
        "\n",
        "    client = speech_v1.SpeechClient()\n",
        "\n",
        "    # local_file_path = 'resources/brooklyn_bridge.raw'\n",
        "\n",
        "    # The language of the supplied audio\n",
        "    language_code = \"en-US\"\n",
        "\n",
        "    # Sample rate in Hertz of the audio data sent\n",
        "    sample_rate_hertz = 44100\n",
        "\n",
        "    # Encoding of audio data sent. This sample sets this explicitly.\n",
        "    # This field is optional for FLAC and WAV audio formats.\n",
        "    \n",
        "    config = {\n",
        "        \"language_code\": language_code,\n",
        "        \"sample_rate_hertz\": sample_rate_hertz,\n",
        "    }\n",
        "\n",
        "    audio = types.RecognitionAudio(uri = storage_uri)\n",
        "\n",
        "    operation = client.long_running_recognize(config, audio)\n",
        "\n",
        "    print(u\"Waiting for operation to complete...\")\n",
        "    response = operation.result()\n",
        "    transcript = []\n",
        "\n",
        "    for result in response.results:\n",
        "        # First alternative is the most probable result\n",
        "        alternative = result.alternatives[0]\n",
        "        transcript.append(u\"{}\".format(alternative.transcript))\n",
        "    separator = \"\"\n",
        "    transcribed = separator.join(transcript)\n",
        "    return(transcribed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCYISVu52Mjd"
      },
      "source": [
        "### Uploading Audio File to the Cloud and Calling the Transcription Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGs7uLPND1Qp"
      },
      "source": [
        "def upload_to_cloud(filename, bucketname):\n",
        "  storage_client = storage.Client.from_service_account_json(\"/content/drive/My Drive/Capstone/instructor-langu-1590688665393-6d06375c82af.json\")\n",
        "  bucket = storage_client.get_bucket(bucketname)\n",
        "  blob = bucket.blob(filename)\n",
        "  blob.upload_from_filename(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWQafdC7tC55"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzwATlKqywCP"
      },
      "source": [
        "### Introduction: Google Cloud Sentiment Analysis\n",
        "\n",
        "Google Cloud has an API that analysis the sentiment in a sentence based on two measures they call the 'score' and the 'magnitude'.\n",
        "\n",
        "The 'score' of a document's sentiment indicates the overall emotion of a document. In other words, it is the NET valence of emotion expressed in the document.\n",
        "\n",
        "The magnitude of a document's sentiment indicates how much emotional content is present within the document, and this value is often proportional to the length of the document. In other words, it serves as a measure of the ratio of words in a document that express emotion (versus the words that are neutral in emotion)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wwO5vvyt8QA"
      },
      "source": [
        "def response_sentiment_analysis(string_response):\n",
        "  text_content = string_response\n",
        "\n",
        "  # Available types: PLAIN_TEXT, HTML\n",
        "  type_ = enums.Document.Type.PLAIN_TEXT\n",
        "\n",
        "  # Optional. If not specified, the language is automatically detected.\n",
        "  # For list of supported languages:\n",
        "  # https://cloud.google.com/natural-language/docs/languages\n",
        "  language = \"en\"\n",
        "  document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
        "\n",
        "  # Available values: NONE, UTF8, UTF16, UTF32\n",
        "  encoding_type = enums.EncodingType.UTF8\n",
        "\n",
        "  client = language_v1.LanguageServiceClient()\n",
        "  annotations = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
        "  return(annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zmdf3M8VLR_"
      },
      "source": [
        "## Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S42QLXeAKMx4"
      },
      "source": [
        "The \"Analyze\" function takes a csv file name, an audio file name, and the instructor names, and performs (a) the transcription and (b) the sentiment analysis on that file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXiJBJPCVR79"
      },
      "source": [
        "def analyze(csvfile, audiofile, instructor, foldername):\n",
        "  filename = audiofile.split(\"/\")\n",
        "  filename = filename[-1]\n",
        "  text_file = filename[:-4]+\".txt\"\n",
        "  print(text_file)\n",
        "  if not glob.glob(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file):\n",
        "    windows_dict = windows_talk(csvfile)\n",
        "    cut_audio(audiofile, filename, windows_dict, instructor)\n",
        "    dst = \"cut_\"+ filename\n",
        "    join_audios(filename, dst)\n",
        "    upload_to_cloud(dst, \"instructor_language\")\n",
        "    transcript = sample_long_running_recognize(\"gs://instructor_language/\"+dst)\n",
        "    text = open(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file, \"w\")\n",
        "    n = text.write(transcript)\n",
        "    text.close()\n",
        "  else:\n",
        "    file = open(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file)\n",
        "    transcript = file.read().replace(\"\\n\", \" \")\n",
        "    file.close()\n",
        "  sentiment_anly = response_sentiment_analysis(transcript)\n",
        "  return (sentiment_anly.document_sentiment.magnitude, sentiment_anly.document_sentiment.score)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcFntQd4KcoO"
      },
      "source": [
        "The \"main\" function performs the analysis on multiple classes, whose audios and csvs are used as inputs. Note that the function also requires one to input the \"instructor\" as a string that exactly matches the string used as an identifier in the CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCNP3H9k3h_c"
      },
      "source": [
        "def main(audios, csvs, instructor, foldername):\n",
        "  if len(audios)!=len(csvs):\n",
        "    print(\"The files are incomplete.\")\n",
        "    return None\n",
        "  df = pd.DataFrame(index = range(len(audios)), columns=[\"Class\", \"Score\", \"Magnitude\"])\n",
        "  for i in range(len(audios)):\n",
        "    score = analyze(csvs[i], audios[i], instructor, foldername)\n",
        "    df.iloc[i, 0] = audios[i].split(\"/\")[-1]\n",
        "    df.iloc[i,2] = score[0]\n",
        "    df.iloc[i,1] = score[1]\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrBHALaHLkjA"
      },
      "source": [
        "audios = glob.glob(\"/content/drive/My Drive/Capstone/McAllister/Audios/*\")\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/McAllister/CSV/*\")\n",
        "\n",
        "data = main(audios, csvs, \"Katie McAllister \", \"McAllister\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/McAllister/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URiIKJuuLXQq"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Terrana/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_10.2.wav']\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/Terrana/CSV/*\") \n",
        "\n",
        "data = main(audios, csvs, \"Alex Terrana \", \"Terrana\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Terrana/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8tBqRuWHOA"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Dosmann/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_10.2.wav']\n",
        "csvs = ['/content/drive/My Drive/Capstone/Dosmann/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_10.2.csv']\n",
        "\n",
        "data = main(audios, csvs, \"Andy Dosmann \", \"Dosmann\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Dosmann/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3hIxBTkZOs1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f5df1eac-933e-42ee-efa2-a96a534e0b45"
      },
      "source": [
        "audios = glob.glob(\"/content/drive/My Drive/Capstone/Fiorelli/Audios/*\")\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/Fiorelli/CSV/*\")\n",
        "\n",
        "print(audios)\n",
        "print(csvs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.2.wav']\n",
            "['/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.2.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG78fkbZYGh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "f6041198-f644-413d-f43f-4f81addd70ef"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.2.wav']\n",
        "csvs = ['/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.2.csv']\n",
        "\n",
        "data = main(audios, csvs, \"Lindsey Fiorelli \", \"Fiorelli\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Fiorelli/results.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class_1.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_1.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_2.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_2.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_3.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_3.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_4.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_4.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_5.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_5.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_6.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_7.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_7.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_8.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_8.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_9.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_9.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_10.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_10.2.txt\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKF8bWgnVSZ4"
      },
      "source": [
        "\n",
        "\n",
        "1.   Import csv file with talk time windows, turn it into a dictionary\n",
        "2.   Import audio, transform it into a concatenated version of the audio with only the instructor's voice\n",
        "3.   Upload audio to Goolge Cloud\n",
        "4.   Run the transcription service, obtain the transcript\n",
        "5.   Run the transcript through sentiment anaysis\n",
        "\n"
      ]
    }
  ]
}