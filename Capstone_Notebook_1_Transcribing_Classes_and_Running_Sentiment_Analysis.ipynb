{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone Notebook 1: Transcribing Classes and Running Sentiment Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UzI6Yn3fZTCuYPzDg6mO6QVWLQes_z51",
      "authorship_tag": "ABX9TyNr+xpG3JxqLh/24DlPOd+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedro-de-bastos/Capstone/blob/master/Capstone_Notebook_1_Transcribing_Classes_and_Running_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2P7Z0m1z4oa"
      },
      "source": [
        "# Capstone Notebook 1: Study 1 - Transcribing Classes and Running Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgdSRuC8fN0n"
      },
      "source": [
        "By: Pedro M. de Bastos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8fDZyVtAN6"
      },
      "source": [
        "## Transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4EYeP3c2WkI"
      },
      "source": [
        "### Installing All Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1aumQzbIILU"
      },
      "source": [
        "#Transcription Prep - run this cell first\n",
        "#Note: this cell may ask you to reset the runtime once after it completes\n",
        "\n",
        "import os\n",
        "!pip install pydub\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install google-cloud-speech\n",
        "!pip install SpeechRecognition\n",
        "!pip install google.cloud\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYEmKu3YAHG"
      },
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import glob\n",
        "import pydub\n",
        "from google.cloud import speech_v1\n",
        "import io\n",
        "from google.cloud import storage\n",
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "from google.cloud.speech_v1 import types\n",
        "\n",
        "\n",
        "#Note: below, I am passing a .json file containing my Google Credentials to a\n",
        "#Environment variable. This is basically allowing you to access your Google\n",
        "#Cloud console through this Python kernel. You'll have to pass your own \n",
        "#.json file location to this variable.\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/Capstone/instructor-langu-1590688665393-6d06375c82af.json'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br08NTBVxFxd"
      },
      "source": [
        "### Introduction: What I'm Doing and How\n",
        "In short, I am using Google Cloud for its Speech-to-text API. Google Cloud Speech-to-text has two main processes for transcribing text from an audio file: synchronous and asynchronous. Synchronous transcription is for short talks (below 1min) and asynchronous transcription is for longer talks (above 1 min). Below, I implement both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b66ebF-801JJ"
      },
      "source": [
        "### Importing the Windows Over Which the Instructor Spoke from a .csv File and Making Adjustments to the Formatting of that Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zw2hFgMM3HF"
      },
      "source": [
        "#Note that the output of the CSV file with talk times for each professor/student\n",
        "#has the timestamp expressed as a string. The function below will be used with \n",
        "#the Pandas \".apply\" method to go through each string and transform it into a \n",
        "#float, expressed in miliseconds since the start of the lesson\n",
        "def string_to_miliseconds(str):\n",
        "  mili = 0\n",
        "  lst = str.split(\":\")\n",
        "  mili += float(lst[2])*1000\n",
        "  mili += float(lst[1])*60*1000\n",
        "  mili += float(lst[0])*60*60*1000\n",
        "  return(mili)\n",
        "\n",
        "def sec_to_milisec(secs):\n",
        "  return secs*1000\n",
        "\n",
        "def windows_talk(filename):\n",
        "  foo = pd.read_csv(filename)\n",
        "  foo = foo[foo['Names'].notnull()]\n",
        "\n",
        "  foo.Timestamp = foo[\"Timestamp\"].apply(string_to_miliseconds)\n",
        "  foo[\"Duration Secs\"] = foo[\"Duration Secs\"].apply(sec_to_milisec)\n",
        "  foo['End'] = foo[\"Timestamp\"]+foo[\"Duration Secs\"] #Creating a new column that indicates when the person stopped talking\n",
        "\n",
        "  names_list = foo.Names.unique()\n",
        "  windows_dict = {}\n",
        "\n",
        "  for name in names_list:\n",
        "    individual = foo['Names'] == name\n",
        "    foo_filtered = foo[individual]\n",
        "    windows_dict[name] = foo_filtered\n",
        "  return windows_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MyWPyfc1VMN"
      },
      "source": [
        "### Cutting Out Instances of the Professor Speaking in Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8re_c4NARrbl"
      },
      "source": [
        "#Audio Pre-Processing: Cutting Audio into Instructor Talk Windows\n",
        "\n",
        "def cut_audio(src, dst, windows_dict, instructor):                                                                     \n",
        "  # importing the instructor's talk time windows and importing the audio file                                                          \n",
        "  test = AudioSegment.from_wav(src)\n",
        "  \n",
        "  try:\n",
        "    windows = windows_dict[instructor]\n",
        "    \n",
        "    for i in range(windows.shape[0]):\n",
        "      test_slice = test[windows.iloc[i,2]:windows.iloc[i,3]]\n",
        "      end = dst +'_slice_' + str(i) + \".wav\"\n",
        "      test_slice.export(end, format='wav')\n",
        "  except:\n",
        "    print(\"Instructor Name Not Valid\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UvODIJw15gY"
      },
      "source": [
        "### Joining the Extracted Professor Responses into One Long Audio For Transcription"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0BVPren7djr"
      },
      "source": [
        "def join_audios(src, dst):\n",
        "  audios = []\n",
        "  for file_name in glob.iglob(src+'_slice_**', recursive=True):\n",
        "    audios.append(file_name)\n",
        "\n",
        "  concat_audio = pydub.AudioSegment.empty()\n",
        "\n",
        "  for audio in audios:\n",
        "    concat_audio += pydub.AudioSegment.from_wav(audio)\n",
        "\n",
        "  concat_audio.export(dst, format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBcq1pm1nAs"
      },
      "source": [
        "### Defining a Function that Takes a .wav File and Transcribes it Using Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn2xGxDUBZh"
      },
      "source": [
        "#Recognizer for long files (over 1 min)\n",
        "\n",
        "def sample_long_running_recognize(storage_uri):\n",
        "    \"\"\"\n",
        "    Transcribe a long audio file using asynchronous speech recognition\n",
        "\n",
        "    Args:\n",
        "      local_file_path Path to local audio file, e.g. /path/audio.wav\n",
        "    \"\"\"\n",
        "\n",
        "    client = speech_v1.SpeechClient()\n",
        "    audio = speech_v1.types.RecognitionAudio(uri = storage_uri)\n",
        "    config = speech_v1.types.RecognitionConfig(language_code = 'en-US', sample_rate_hertz=44100)\n",
        "    operation = client.long_running_recognize(config=config, audio=audio)\n",
        "\n",
        "    print(u\"Waiting for operation to complete...\")\n",
        "    response = operation.result()\n",
        "    transcript = []\n",
        "\n",
        "    for result in response.results:\n",
        "        # First alternative is the most probable result\n",
        "        alternative = result.alternatives[0]\n",
        "        transcript.append(u\"{}\".format(alternative.transcript))\n",
        "    separator = \"\"\n",
        "    transcribed = separator.join(transcript)\n",
        "    return(transcribed)\n",
        "\n",
        "def sample_short_recognize(storage_uri):\n",
        "    client = speech_v1.SpeechClient()\n",
        "    audio = speech_v1.types.RecognitionAudio(uri = storage_uri)\n",
        "    config = speech_v1.types.RecognitionConfig(language_code = 'en-US', sample_rate_hertz=44100)\n",
        "    operation = client.recognize(config=config, audio=audio)\n",
        "\n",
        "    print(u\"Waiting for operation to complete...\")\n",
        "    \"\"\"response = operation.result()\n",
        "    transcript = []\n",
        "\n",
        "    for result in response.results:\n",
        "        # First alternative is the most probable result\n",
        "        alternative = result.alternatives[0]\n",
        "        transcript.append(u\"{}\".format(alternative.transcript))\n",
        "    separator = \"\"\n",
        "    transcribed = separator.join(transcript)\"\"\"\n",
        "    return(operation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6JCrHhYd0Z0"
      },
      "source": [
        "### Slice Analysis Section: Producing Slice CSVs for Each Class\n",
        "\n",
        "For Study 2 in my project I decided to, instead of joining every comment the professor made for the class and transcribing the whole thing, transcibe each comment separately, so that I could then run sentiment analysis on it. The code below, thus, transcribes each comment. You will notice that I implemented memoization by savning my progress as csv files once they are done. This means that, although the algorithm iterates over all the data for all the professors, it will only transcribe classes that are not yet complete and store the transcriptions within my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wke8BIlaSvQZ"
      },
      "source": [
        "#### \n",
        "import glob\n",
        "\n",
        "def produce_class_transcripts(session, instructor):\n",
        "  if not glob.glob(\"/content/drive/MyDrive/Capstone/{}/Slice Analysis/{}.csv\".format([i for i in instructor.split()][-1], session)):\n",
        "    inst = [i.lower() for i in instructor.split()][-1]\n",
        "\n",
        "    windows = windows_talk(\"/content/drive/MyDrive/Capstone/{}/CSV/Class_{}.csv\".format([i for i in instructor.split()][-1], session))\n",
        "\n",
        "    cut_audio(\"/content/drive/MyDrive/Capstone/{}/Audios/Class_{}.wav\".format([i for i in instructor.split()][-1], session), inst+'_{}'.format(session), windows, instructor)\n",
        "\n",
        "    cut_audios = glob.glob('{}_{}*.wav'.format(inst, session))\n",
        "    \n",
        "    foo = windows[instructor]\n",
        "    foo['Files'] = [\"{}_{}_slice_\".format(inst, session)+str(i)+\".wav\" for i in range(len(cut_audios))]\n",
        "    foo['URIs'] = [\"gs://instructor_language/\"+\"{}_{}_slice_\".format(inst, session)+str(i)+\".wav\" for i in range(len(cut_audios))]\n",
        "\n",
        "    foo[\"Files\"].apply(upload_to_cloud, args=('instructor_language',))\n",
        "    foo['Transcripts'] = foo['URIs'].apply(sample_long_running_recognize)\n",
        "    foo.to_csv(\"/content/drive/MyDrive/Capstone/{}/Slice Analysis/{}.csv\".format([i for i in instructor.split()][-1], session))\n",
        "    return foo\n",
        "  return pd.read_csv(\"/content/drive/MyDrive/Capstone/{}/Slice Analysis/{}.csv\".format([i for i in instructor.split()][-1], session))\n",
        "\n",
        "professors = [\"Katie McAllister \", \"Alex Terrana \", \"Andy Dosmann \", \"Lindsey Fiorelli \"]\n",
        "sessions = []\n",
        "for i in range(1, 11):\n",
        "  for j in range(1, 3):\n",
        "    prop = str(i)+\".\"+str(j)\n",
        "    if not prop == '6.1':\n",
        "      sessions.append(prop)\n",
        "\n",
        "for prof in professors:\n",
        "  for sess in sessions:\n",
        "    produce_class_transcripts(float(sess), prof)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCYISVu52Mjd"
      },
      "source": [
        "### Uploading Audio File to the Cloud and Calling the Transcription Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGs7uLPND1Qp"
      },
      "source": [
        "def upload_to_cloud(filename, bucketname):\n",
        "  storage_client = storage.Client.from_service_account_json(\"/content/drive/My Drive/Capstone/instructor-langu-1590688665393-6d06375c82af.json\")\n",
        "  \n",
        "  blobs=[]\n",
        "  client = storage.Client()\n",
        "  for blob in client.list_blobs('instructor_language'):\n",
        "    blobs.append(str(blob).split()[-2])\n",
        "\n",
        "  if filename+\",\" in blobs:\n",
        "    return\n",
        "  \n",
        "  bucket = storage_client.get_bucket(bucketname)\n",
        "  blob = bucket.blob(filename)\n",
        "  blob.upload_from_filename(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWQafdC7tC55"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzwATlKqywCP"
      },
      "source": [
        "### Introduction: Google Cloud Sentiment Analysis\n",
        "\n",
        "Google Cloud has an API that analyzes the sentiment in a sentence based on two measures they call the 'score' and the 'magnitude'.\n",
        "\n",
        "The 'score' of a document's sentiment indicates the overall emotion of a document. In other words, it is the NET valence of emotion expressed in the document.\n",
        "\n",
        "The magnitude of a document's sentiment indicates how much emotional content is present within the document, and this value is often proportional to the length of the document. In other words, it serves as a measure of the ratio of words in a document that express emotion (versus the words that are neutral in emotion).\n",
        "\n",
        "I use the code below for the evaluation of the entire class' stranscription (study 1 in my capstone paper)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wwO5vvyt8QA"
      },
      "source": [
        "def response_sentiment_analysis(string_response):\n",
        "  text_content = string_response\n",
        "\n",
        "  # Available types: PLAIN_TEXT, HTML\n",
        "  type_ = enums.Document.Type.PLAIN_TEXT\n",
        "\n",
        "  # Optional. If not specified, the language is automatically detected.\n",
        "  # For list of supported languages:\n",
        "  # https://cloud.google.com/natural-language/docs/languages\n",
        "  language = \"en\"\n",
        "  document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
        "\n",
        "  # Available values: NONE, UTF8, UTF16, UTF32\n",
        "  encoding_type = enums.EncodingType.UTF8\n",
        "\n",
        "  client = language_v1.LanguageServiceClient()\n",
        "  annotations = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
        "  return(annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zmdf3M8VLR_"
      },
      "source": [
        "## Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S42QLXeAKMx4"
      },
      "source": [
        "The \"Analyze\" function takes a csv file name, an audio file name, and the instructor names, and performs (a) the transcription and (b) the sentiment analysis on that file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXiJBJPCVR79"
      },
      "source": [
        "def analyze(csvfile, audiofile, instructor, foldername):\n",
        "  filename = audiofile.split(\"/\")\n",
        "  filename = filename[-1]\n",
        "  text_file = filename[:-4]+\".txt\"\n",
        "  print(text_file)\n",
        "  if not glob.glob(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file):\n",
        "    windows_dict = windows_talk(csvfile)\n",
        "    cut_audio(audiofile, filename, windows_dict, instructor)\n",
        "    dst = \"cut_\"+ filename\n",
        "    join_audios(filename, dst)\n",
        "    upload_to_cloud(dst, \"instructor_language\")\n",
        "    transcript = sample_long_running_recognize(\"gs://instructor_language/\"+dst)\n",
        "    text = open(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file, \"w\")\n",
        "    n = text.write(transcript)\n",
        "    text.close()\n",
        "  else:\n",
        "    file = open(\"/content/drive/My Drive/Capstone/\"+foldername+\"/Transcripts/\"+text_file)\n",
        "    transcript = file.read().replace(\"\\n\", \" \")\n",
        "    file.close()\n",
        "  sentiment_anly = response_sentiment_analysis(transcript)\n",
        "  return (sentiment_anly.document_sentiment.magnitude, sentiment_anly.document_sentiment.score)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcFntQd4KcoO"
      },
      "source": [
        "The \"main\" function performs the analysis on multiple classes, whose audios and csvs are used as inputs. Note that the function also requires one to input the \"instructor\" as a string that exactly matches the string used as an identifier in the CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCNP3H9k3h_c"
      },
      "source": [
        "def main(audios, csvs, instructor, foldername):\n",
        "  if len(audios)!=len(csvs):\n",
        "    print(\"The files are incomplete.\")\n",
        "    return None\n",
        "  df = pd.DataFrame(index = range(len(audios)), columns=[\"Class\", \"Score\", \"Magnitude\"])\n",
        "  for i in range(len(audios)):\n",
        "    score = analyze(csvs[i], audios[i], instructor, foldername)\n",
        "    df.iloc[i, 0] = audios[i].split(\"/\")[-1]\n",
        "    df.iloc[i,2] = score[0]\n",
        "    df.iloc[i,1] = score[1]\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR4z-EDGfD4i"
      },
      "source": [
        "### Running the Main Function Separately for Each Professor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrBHALaHLkjA"
      },
      "source": [
        "audios = glob.glob(\"/content/drive/My Drive/Capstone/McAllister/Audios/*\")\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/McAllister/CSV/*\")\n",
        "\n",
        "data = main(audios, csvs, \"Katie McAllister \", \"McAllister\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/McAllister/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URiIKJuuLXQq"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Terrana/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Terrana/Audios/Class_10.2.wav']\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/Terrana/CSV/*\") \n",
        "\n",
        "data = main(audios, csvs, \"Alex Terrana \", \"Terrana\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Terrana/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8tBqRuWHOA"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Dosmann/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Dosmann/Audios/Class_10.2.wav']\n",
        "csvs = ['/content/drive/My Drive/Capstone/Dosmann/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Dosmann/CSV/Class_10.2.csv']\n",
        "\n",
        "data = main(audios, csvs, \"Andy Dosmann \", \"Dosmann\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Dosmann/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3hIxBTkZOs1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f5df1eac-933e-42ee-efa2-a96a534e0b45"
      },
      "source": [
        "audios = glob.glob(\"/content/drive/My Drive/Capstone/Fiorelli/Audios/*\")\n",
        "csvs = glob.glob(\"/content/drive/My Drive/Capstone/Fiorelli/CSV/*\")\n",
        "\n",
        "print(audios)\n",
        "print(csvs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.2.wav']\n",
            "['/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.2.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG78fkbZYGh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "f6041198-f644-413d-f43f-4f81addd70ef"
      },
      "source": [
        "audios = ['/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_1.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_2.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_3.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_4.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_5.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_6.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_7.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_8.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_9.2.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.1.wav', '/content/drive/My Drive/Capstone/Fiorelli/Audios/Class_10.2.wav']\n",
        "csvs = ['/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_1.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_2.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_3.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_4.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_5.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_6.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_7.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_8.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_9.2.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.1.csv', '/content/drive/My Drive/Capstone/Fiorelli/CSV/Class_10.2.csv']\n",
        "\n",
        "data = main(audios, csvs, \"Lindsey Fiorelli \", \"Fiorelli\")\n",
        "data.head\n",
        "data.to_csv(\"/content/drive/My Drive/Capstone/Fiorelli/results.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class_1.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_1.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_2.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_2.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_3.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_3.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_4.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_4.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_5.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_5.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_6.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_7.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_7.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_8.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_8.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_9.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_9.2.txt\n",
            "Waiting for operation to complete...\n",
            "Class_10.1.txt\n",
            "Waiting for operation to complete...\n",
            "Class_10.2.txt\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}